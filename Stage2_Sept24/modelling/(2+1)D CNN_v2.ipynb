{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe289802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow.keras.layers as layers\n",
    "from data_generator import NpyDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam,Adagrad\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from tensorflow.keras.layers import *\n",
    "# import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62f6c707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:  4200\n",
      "Test samples:  1800\n"
     ]
    }
   ],
   "source": [
    "train_path = \"/media/kashraf/TOSHIBA EXT/Dissertation/stage2/EEG movie/Theta/train\"\n",
    "test_path = \"/media/kashraf/TOSHIBA EXT/Dissertation/stage2/EEG movie/Theta/test\"\n",
    "train_gen = NpyDataGenerator(train_path,batch_size=4)\n",
    "validation_gen = NpyDataGenerator(test_path,batch_size=1,shuffle=False)\n",
    "print(\"Training samples: \",train_gen.num_samples)\n",
    "print(\"Test samples: \",validation_gen.num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "489b0501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = \"/media/kashraf/TOSHIBA EXT/Dissertation/stage2/wavelet/train_real/cl8/ERP8_6.npy\"\n",
    "# data= np.load(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38d0ca3",
   "metadata": {},
   "source": [
    "### (2+1)D CNN\n",
    "Unlike 3D CNN, in (2+1)D CNN we factorize the convolution. Instead of a single 3D convolution to process the time and space dimensions,a \"(2+1)D\" convolution processes the space and time dimensions separately. The figure below shows the factored spatial and temporal convolutions of a (2 + 1)D convolution.\n",
    "![(2+1)D convolutions](https://www.tensorflow.org/images/tutorials/video/2plus1CNN.png)\n",
    "figure source: https://www.tensorflow.org/images/. \n",
    "The main advantage of this approach is that it reduces the number of parameters. In the (2 + 1)D convolution the spatial convolution takes in data of the shape `(1, width, height)`, while the temporal convolution takes in data of the shape `(time, 1, 1)`. For example, a (2 + 1)D convolution with kernel size `(3 x 3 x 3)` would need weight matrices of size `(9 * channels**2) + (3 * channels**2)`, less than half as many as the full 3D convolution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb1d25a",
   "metadata": {},
   "source": [
    "### Residual block\n",
    "A ResNet model is made from a sequence of residual blocks. A residual block has two branches. The main branch performs the calculation, but is difficult for gradients to flow through. The residual branch bypasses the main calculation and mostly just adds the input to the output of the main branch. Gradients flow easily through this branch. Therefore, an easy path from the loss function to any of the residual block's main branch will be present. This avoids the vanishing gradient problem.\n",
    "\n",
    "Create the main branch of the residual block with the following class. In contrast to the standard ResNet structure this uses the custom Conv2Plus1D layer instead of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0495e0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def Conv2Plus1D(filters, kernel_size, padding='same'):\n",
    "    \"\"\"A custom layer for 2D convolution followed by 1D convolution.\"\"\"\n",
    "    def layer(x):\n",
    "        # First apply spatial convolution\n",
    "        x = layers.Conv3D(filters, (1, kernel_size[1], kernel_size[2]), padding=padding)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.ReLU()(x)\n",
    "        # Followed by temporal convolution\n",
    "        x = layers.Conv3D(filters, (kernel_size[0], 1, 1), padding=padding)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.ReLU()(x)\n",
    "        return x\n",
    "    return layer\n",
    "\n",
    "def add_residual_block(input_tensor, filters, kernel_size, stride=(1, 1, 1)):\n",
    "    \"\"\"Add a residual block with optional downsampling.\"\"\"\n",
    "    # Main path\n",
    "    x = Conv2Plus1D(filters, kernel_size, padding='same')(input_tensor)\n",
    "    x = layers.MaxPooling3D(pool_size=(1, 2, 2), strides=stride, padding='same')(x)\n",
    "\n",
    "    # Residual path\n",
    "    if input_tensor.shape[-1] != filters or stride != (1, 1, 1):\n",
    "        # Adjust dimensions via 1x1 convolutions if number of filters or stride changes\n",
    "        res = layers.Conv3D(filters, (1, 1, 1), strides=stride, padding='same')(input_tensor)\n",
    "        res = layers.BatchNormalization()(res)\n",
    "    else:\n",
    "        res = input_tensor\n",
    "\n",
    "    # Combine main path with residual path\n",
    "    x = layers.add([x, res])\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "# Input tensor for a 3D model\n",
    "input_shape = (176, 64, 28, 1)  # (time, height, width, channels)\n",
    "input_tensor = layers.Input(shape=input_shape)\n",
    "\n",
    "# Initial convolution layer\n",
    "x = Conv2Plus1D(16, (3, 7, 7))(input_tensor)\n",
    "x = layers.MaxPooling3D(pool_size=(1, 2, 2), padding='same')(x)\n",
    "\n",
    "# Adding residual blocks\n",
    "x = add_residual_block(x, 32, (3, 3, 3))\n",
    "x = add_residual_block(x, 64, (3, 3, 3), stride=(2, 2, 2))\n",
    "x = add_residual_block(x, 128, (3, 3, 3), stride=(2, 2, 2))\n",
    "x = add_residual_block(x, 256, (3, 3, 3), stride=(2, 2, 2))\n",
    "\n",
    "# Final global pooling and dense layer\n",
    "x = layers.GlobalAveragePooling3D()(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)  # Dropout added for regularization\n",
    "x = layers.Dense(4)(x)  # Assuming 4 is the number of output classes or features\n",
    "\n",
    "model = models.Model(inputs=input_tensor, outputs=x)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf1d154",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69767c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mixed precision policy\n",
    "mixed_precision = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "tf.keras.mixed_precision.experimental.set_policy(mixed_precision)             \n",
    "checkpoint = ModelCheckpoint(\"/media/kashraf/TOSHIBA EXT/Dissertation/stage2/modeling/weights/3D_CNN_WT.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 20,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                              factor = 0.01,\n",
    "                              patience = 5,\n",
    "                              verbose = 1,\n",
    "                              min_delta = 0.000001)\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [ checkpoint,reduce_lr,earlystop]\n",
    "\n",
    "# We use a very small learning rate \n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = Adam(learning_rate=0.0001),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "# history= model.fit(   \n",
    "#     train_gen,\n",
    "#     epochs = epochs,\n",
    "#     callbacks =callbacks,\n",
    "#     validation_data = validation_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc006357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 78 Complete [01h 40m 20s]\n",
      "val_accuracy: 0.2688888907432556\n",
      "\n",
      "Best val_accuracy So Far: 0.27388888597488403\n",
      "Total elapsed time: 13h 06m 19s\n",
      "\n",
      "Search: Running Trial #79\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "num_layers        |2                 |1                 \n",
      "kernel_size_0     |3x7x7             |3x7x7             \n",
      "filters_0         |128               |64                \n",
      "activation        |relu              |relu              \n",
      "batch_norm_0      |True              |True              \n",
      "pooling_type_0    |avg               |avg               \n",
      "dropout_conv_0    |0.4               |0                 \n",
      "dense_units       |256               |512               \n",
      "dense_activation  |relu              |relu              \n",
      "dropout_dense     |0                 |0.5               \n",
      "optimizer         |rmsprop           |rmsprop           \n",
      "lr_adam           |0.00034109        |0.0056664         \n",
      "kernel_size_1     |3x5x5             |3x5x5             \n",
      "filters_1         |64                |32                \n",
      "batch_norm_1      |True              |False             \n",
      "pooling_type_1    |avg               |avg               \n",
      "dropout_conv_1    |0.4               |0.1               \n",
      "kernel_size_2     |3x7x7             |3x3x3             \n",
      "filters_2         |16                |64                \n",
      "batch_norm_2      |False             |True              \n",
      "pooling_type_2    |max               |max               \n",
      "dropout_conv_2    |0                 |0.4               \n",
      "lr_sgd            |0.0029811         |0.0064536         \n",
      "kernel_size_3     |3x7x7             |3x3x3             \n",
      "filters_3         |32                |64                \n",
      "batch_norm_3      |False             |False             \n",
      "pooling_type_3    |avg               |avg               \n",
      "dropout_conv_3    |0.1               |0.2               \n",
      "lr_rmsprop        |0.00052155        |0.0001            \n",
      "kernel_size_4     |3x5x5             |None              \n",
      "filters_4         |64                |None              \n",
      "batch_norm_4      |True              |None              \n",
      "pooling_type_4    |avg               |None              \n",
      "dropout_conv_4    |0.3               |None              \n",
      "tuner/epochs      |50                |50                \n",
      "tuner/initial_e...|0                 |17                \n",
      "tuner/bracket     |0                 |3                 \n",
      "tuner/round       |0                 |3                 \n",
      "\n",
      "Epoch 1/50\n",
      "   6/1050 [..............................] - ETA: 5:48 - loss: 6.3267 - accuracy: 0.3271WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1142s vs `on_train_batch_end` time: 0.2199s). Check your callbacks.\n",
      "1050/1050 [==============================] - 400s 380ms/step - loss: 11.4939 - accuracy: 0.2574 - val_loss: 12.0919 - val_accuracy: 0.2500\n",
      "Epoch 2/50\n",
      "1050/1050 [==============================] - 398s 379ms/step - loss: 14.6272 - accuracy: 0.2305 - val_loss: 11.4349 - val_accuracy: 0.2494\n",
      "Epoch 3/50\n",
      "1050/1050 [==============================] - 399s 380ms/step - loss: 13.8787 - accuracy: 0.2512 - val_loss: 20.1476 - val_accuracy: 0.2500\n",
      "Epoch 4/50\n",
      "1050/1050 [==============================] - 399s 380ms/step - loss: 12.5917 - accuracy: 0.2695 - val_loss: 19.7414 - val_accuracy: 0.2544\n",
      "Epoch 5/50\n",
      "1050/1050 [==============================] - 399s 380ms/step - loss: 15.9370 - accuracy: 0.2626 - val_loss: 8.0591 - val_accuracy: 0.2500\n",
      "Epoch 6/50\n",
      "1050/1050 [==============================] - 400s 381ms/step - loss: 13.0441 - accuracy: 0.2691 - val_loss: 12.4758 - val_accuracy: 0.2406\n",
      "Epoch 7/50\n",
      "1050/1050 [==============================] - 399s 380ms/step - loss: 12.8665 - accuracy: 0.2622 - val_loss: 16.0469 - val_accuracy: 0.2378\n",
      "Epoch 8/50\n",
      "1050/1050 [==============================] - 399s 380ms/step - loss: 12.4070 - accuracy: 0.2469 - val_loss: 11.5235 - val_accuracy: 0.2606\n",
      "Epoch 9/50\n",
      "1050/1050 [==============================] - 399s 380ms/step - loss: 11.9846 - accuracy: 0.2488 - val_loss: 9.8366 - val_accuracy: 0.2511\n",
      "Epoch 10/50\n",
      "1050/1050 [==============================] - 399s 380ms/step - loss: 10.5733 - accuracy: 0.2479 - val_loss: 12.7528 - val_accuracy: 0.2611\n",
      "Epoch 11/50\n",
      "1050/1050 [==============================] - 398s 379ms/step - loss: 12.8866 - accuracy: 0.2715 - val_loss: 11.7693 - val_accuracy: 0.2644\n",
      "Epoch 12/50\n",
      "1050/1050 [==============================] - 398s 379ms/step - loss: 11.9881 - accuracy: 0.2593 - val_loss: 10.1508 - val_accuracy: 0.2439\n",
      "Epoch 13/50\n",
      "1050/1050 [==============================] - 399s 380ms/step - loss: 12.1367 - accuracy: 0.2493 - val_loss: 11.8003 - val_accuracy: 0.2633\n",
      "Epoch 14/50\n",
      "1050/1050 [==============================] - 399s 380ms/step - loss: 12.4275 - accuracy: 0.2533 - val_loss: 12.1512 - val_accuracy: 0.2500\n",
      "Epoch 15/50\n",
      "1050/1050 [==============================] - 399s 380ms/step - loss: 11.8396 - accuracy: 0.2562 - val_loss: 12.0246 - val_accuracy: 0.2678\n",
      "Epoch 16/50\n",
      "1050/1050 [==============================] - 399s 380ms/step - loss: 11.9135 - accuracy: 0.2647 - val_loss: 12.2870 - val_accuracy: 0.2656\n",
      "Epoch 17/50\n",
      "1050/1050 [==============================] - 399s 380ms/step - loss: 12.1647 - accuracy: 0.2657 - val_loss: 12.0941 - val_accuracy: 0.2444\n",
      "Epoch 18/50\n",
      "1050/1050 [==============================] - 399s 380ms/step - loss: 11.9687 - accuracy: 0.2483 - val_loss: 12.1513 - val_accuracy: 0.2578\n",
      "Epoch 19/50\n",
      " 238/1050 [=====>........................] - ETA: 4:30 - loss: 11.6149 - accuracy: 0.2550"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from kerastuner import HyperModel, Hyperband, Tuner\n",
    "\n",
    "\n",
    "\n",
    "class CNN3DHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "    \n",
    "    def build(self, hp):\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Input(shape=self.input_shape))\n",
    "        \n",
    "        # Hyperparameters for convolutional layers\n",
    "        for i in range(hp.Int('num_layers', 1, 5)):\n",
    "            kernel_size = hp.Choice(f'kernel_size_{i}', ['3x3x3', '3x5x5', '3x7x7'])\n",
    "            kernel_size = tuple(map(int, kernel_size.split('x')))\n",
    "            \n",
    "            model.add(layers.Conv3D(\n",
    "                filters=hp.Choice(f'filters_{i}', [16, 32, 64,128]),\n",
    "                kernel_size=kernel_size,\n",
    "                activation=hp.Choice('activation', ['relu']),\n",
    "                padding='same'\n",
    "            ))\n",
    "            if hp.Boolean(f'batch_norm_{i}'):\n",
    "                model.add(layers.BatchNormalization())\n",
    "\n",
    "            # Pooling layer choice\n",
    "            if hp.Choice(f'pooling_type_{i}', ['max', 'avg']) == 'max':\n",
    "                model.add(layers.MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "            else:\n",
    "                model.add(layers.AveragePooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "            # Dropout in convolutional blocks\n",
    "            model.add(layers.Dropout(rate=hp.Float(f'dropout_conv_{i}', 0, 0.5, step=0.1)))\n",
    "        \n",
    "        # Global pooling before the dense layers\n",
    "        model.add(layers.GlobalAveragePooling3D())\n",
    "\n",
    "        # Dense layer\n",
    "        model.add(layers.Dense(\n",
    "            units=hp.Int('dense_units', 256, 1024, step=64),\n",
    "            activation=hp.Choice('dense_activation', ['relu'])\n",
    "        ))\n",
    "\n",
    "        # Dropout after dense layer\n",
    "        model.add(layers.Dropout(rate=hp.Float('dropout_dense', 0, 0.5, step=0.1)))\n",
    "\n",
    "        # Output layer\n",
    "        model.add(layers.Dense(4))  # Assuming 4 is the number of output classes\n",
    "        \n",
    "        # Compile model\n",
    "        optimizer_choice = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])\n",
    "        if optimizer_choice == 'adam':\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=hp.Float('lr_adam', 1e-4, 1e-2, sampling='log'))\n",
    "        elif optimizer_choice == 'sgd':\n",
    "            optimizer = tf.keras.optimizers.SGD(learning_rate=hp.Float('lr_sgd', 1e-4, 1e-2, sampling='log'))\n",
    "        else:\n",
    "            optimizer = tf.keras.optimizers.RMSprop(learning_rate=hp.Float('lr_rmsprop', 1e-4, 1e-2, sampling='log'))\n",
    "        \n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "\n",
    "input_shape = (64, 64, 176, 1)  # (time, height, width, channels)\n",
    "hypermodel = CNN3DHyperModel(input_shape=input_shape)\n",
    "\n",
    "# Hyperparameter tuner configuration using Hyperband\n",
    "tuner = Hyperband(\n",
    "    hypermodel,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=50,\n",
    "    hyperband_iterations=4,\n",
    "    directory='hyperband',\n",
    "    project_name='3d_cnn_opt'\n",
    ")\n",
    "\n",
    "# Assuming you have loaded and preprocessed your dataset\n",
    "# train_data, train_labels, val_data, val_labels = load_data()\n",
    "\n",
    "# Hyperparameter search\n",
    "tuner.search(train_gen,epochs=50, validation_data=validation_gen)\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\"\"\n",
    "The best number of layers: {best_hps.get('num_layers')}\n",
    "The best activation function: {best_hps.get('activation')}\n",
    "The best pooling type: {best_hps.get('pooling_type_0')}  # Example for the first layer\n",
    "The best number of filters: {best_hps.get('filters_0')}  # Example for the first layer\n",
    "The best optimizer: {best_hps.get('optimizer')}\n",
    "The best learning rate: {best_hps.get('lr_' + best_hps.get('optimizer'))}\n",
    "The best number of dense units: {best_hps.get('dense_units')}\n",
    "The best dropout rate in conv layers: {best_hps.get('dropout_conv_0')}  # Example for the first layer\n",
    "The best dropout rate after dense layer: {best_hps.get('dropout_dense')}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2185ca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"/media/kashraf/Elements/Dissertation/modelling/General/results/AE_denoised/figures/beta/2+1D CNN\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf708e2",
   "metadata": {},
   "source": [
    "### Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34272c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.xticks(fontsize=13,weight=\"bold\")\n",
    "plt.yticks(fontsize=13,weight=\"bold\")\n",
    "loss_values = history.history['loss']\n",
    "val_loss_values = history.history['val_loss']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "line1 = plt.plot(epochs, val_loss_values, label='Validation Loss')\n",
    "line2 = plt.plot(epochs, loss_values, label='Training Loss')\n",
    "plt.setp(line1, linewidth=3.0,marker = '+', markersize=10.0)\n",
    "plt.setp(line2, linewidth=3.0,marker = '4', markersize=10.0)\n",
    "plt.xlabel('Epochs',fontsize=20,weight=\"bold\") \n",
    "plt.ylabel('Loss',fontsize=20,weight=\"bold\")\n",
    "plt.grid(True)\n",
    "plt.xticks(fontsize=15,weight=\"bold\")\n",
    "plt.yticks(fontsize=15,weight=\"bold\")\n",
    "plt.legend(fontsize=20,loc = \"upper center\")\n",
    "plt.savefig(os.path.join(results_path,'Loss_3D_CNN_rms_V2.png'),bbox_inches =\"tight\",pad_inches =0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6abdabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.xticks(fontsize=13,weight=\"bold\")\n",
    "plt.yticks(fontsize=13,weight=\"bold\")\n",
    "acc_values = history.history['accuracy']\n",
    "val_acc_values = history.history['val_accuracy']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "line1 = plt.plot(epochs, val_acc_values, label='Validation Accuracy')\n",
    "line2 = plt.plot(epochs, acc_values , label='Training Accuracy')\n",
    "plt.setp(line1, linewidth=3.0,marker = '+', markersize=10.0)\n",
    "plt.setp(line2, linewidth=3.0,marker = '4', markersize=10.0)\n",
    "plt.xlabel('Epochs',fontsize=20,weight=\"bold\") \n",
    "plt.ylabel('Loss',fontsize=20,weight=\"bold\")\n",
    "plt.grid(True)\n",
    "plt.xticks(fontsize=15,weight=\"bold\")\n",
    "plt.yticks(fontsize=15,weight=\"bold\")\n",
    "plt.legend(fontsize=20,loc= \"lower center\")\n",
    "plt.savefig(os.path.join(results_path,'Accuracy_3D_CNN_rms_V2.png'),bbox_inches =\"tight\",pad_inches =0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1be15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sr\n",
    "import pandas as pd\n",
    "# model= load_model(\"/media/kashraf/Elements/Dissertation/modelling/General/weights/3D_CNN.h5\")\n",
    "validation_gen = NpyDataGenerator(test_path,batch_size=4,shuffle=False)\n",
    "_, y_test, _ = validation_gen[0]\n",
    "y_pred= np.argmax(model.predict(validation_gen), axis=1)\n",
    "\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "class_names=[\"CL_1\",\"CL_2\",\"CL_3\",\"CL_4\"]\n",
    "# report=classi(y_test,y_pred,target_names=class_names)\n",
    "np.save(os.path.join(results_path,'Report_beta_3D_CNN.npy'),report)\n",
    "\n",
    "conf=confusion_matrix(y_test,y_pred,normalize=\"true\")\n",
    "conf_df=pd.DataFrame(conf, index=class_names, columns=class_names)\n",
    "# print(\"\\nFace  accuracy =\",accuracy)\n",
    "# print(\"\\n Classification report: \\n\",report)\n",
    "fig=plt.figure(figsize=(15,10))\n",
    "sr.heatmap(conf_df,annot=True,cmap=\"Blues\")\n",
    "# plt.title(\"Confusion matrix\")\n",
    "plt.savefig(os.path.join(results_path,'Conf_Mat_beta_3D_CNN_V1.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9b70bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen.npy_files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
