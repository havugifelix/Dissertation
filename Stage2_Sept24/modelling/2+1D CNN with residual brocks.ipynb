{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feb832b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 16:22:50.501267: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "/home/kashraf/.local/lib/python3.8/site-packages/scipy/__init__.py:143: UserWarning: A NumPy version >=1.19.5 and <1.27.0 is required for this version of SciPy (detected version 1.19.2)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow.keras.layers as layers\n",
    "from data_generator import NpyDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam,Adagrad\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from tensorflow.keras.layers import *\n",
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bde9a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:  4200\n",
      "Test samples:  1800\n"
     ]
    }
   ],
   "source": [
    "train_path = \"/media/kashraf/TOSHIBA EXT/Dissertation/stage2/EEG movie/Theta/train\"\n",
    "test_path = \"/media/kashraf/TOSHIBA EXT/Dissertation/stage2/EEG movie/Theta/test\"\n",
    "train_gen = NpyDataGenerator(train_path,batch_size=8)\n",
    "validation_gen = NpyDataGenerator(test_path,batch_size=1,shuffle=False)\n",
    "print(\"Training samples: \",train_gen.num_samples)\n",
    "print(\"Test samples: \",validation_gen.num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "782fba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2Plus1D(keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, padding):\n",
    "        super().__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.seq = keras.Sequential([\n",
    "            # Spatial decomposition\n",
    "            layers.Conv3D(filters=filters,\n",
    "                          kernel_size=(kernel_size[0], kernel_size[1], 1),\n",
    "                          padding=padding),\n",
    "            # Temporal decomposition\n",
    "            layers.Conv3D(filters=filters,\n",
    "                          kernel_size=(1, 1, kernel_size[2]),\n",
    "                          padding=padding)\n",
    "        ])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'filters': self.filters,\n",
    "            'kernel_size': self.kernel_size,\n",
    "            'padding': self.padding\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "\n",
    "\n",
    "class ResidualMain(keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size):\n",
    "        super().__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.seq = keras.Sequential([\n",
    "            Conv2Plus1D(filters=filters,\n",
    "                        kernel_size=kernel_size,\n",
    "                        padding='same'),\n",
    "            layers.LayerNormalization(),\n",
    "            layers.ReLU(),\n",
    "            Conv2Plus1D(filters=filters, \n",
    "                        kernel_size=kernel_size,\n",
    "                        padding='same'),\n",
    "            layers.LayerNormalization()])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'filters': self.filters,\n",
    "            'kernel_size': self.kernel_size\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "    \n",
    "class Project(keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.seq = keras.Sequential([\n",
    "            layers.Dense(units),\n",
    "            layers.LayerNormalization()\n",
    "        ])\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'units': self.units,\n",
    "        })\n",
    "        return config\n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "    \n",
    "def add_residual_block(input, filters, kernel_size):\n",
    "    out = ResidualMain(filters, kernel_size)(input)\n",
    "    res = input\n",
    "  # Using the Keras functional APIs, project the last dimension of the tensor to\n",
    "  # match the new filter size\n",
    "    if out.shape[-1] != input.shape[-1]:\n",
    "        res = Project(out.shape[-1])(res)\n",
    "\n",
    "    return layers.add([res, out])\n",
    "\n",
    "class ResizeVideo(keras.layers.Layer):\n",
    "    def __init__(self, height, width):\n",
    "        super().__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.resizing_layer = layers.experimental.preprocessing.Resizing(self.height, self.width)\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'height': self.height,\n",
    "            'width': self.width,\n",
    "        })\n",
    "        return config\n",
    "    @tf.function\n",
    "    def call(self, video):\n",
    "        old_shape = einops.parse_shape(video, 'b t h w c')\n",
    "        images = einops.rearrange(video, 'b t h w c -> (b t) h w c')\n",
    "        images = self.resizing_layer(images)\n",
    "        videos = einops.rearrange(images, '(b t) h w c -> b t h w c',t = old_shape['t'])\n",
    "        return videos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58746e72",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0b10b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33775452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 16:22:52.357196: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-08-11 16:22:52.358315: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2024-08-11 16:22:52.389441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 16:22:52.389607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2024-08-11 16:22:52.389619: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-08-11 16:22:52.390758: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2024-08-11 16:22:52.390784: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2024-08-11 16:22:52.391843: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-08-11 16:22:52.392013: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-08-11 16:22:52.393182: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-08-11 16:22:52.393812: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-08-11 16:22:52.396246: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-08-11 16:22:52.396346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 16:22:52.396530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 16:22:52.396619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2024-08-11 16:22:52.396940: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-11 16:22:52.397266: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-08-11 16:22:52.397330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 16:22:52.397429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2024-08-11 16:22:52.397441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-08-11 16:22:52.397456: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2024-08-11 16:22:52.397467: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2024-08-11 16:22:52.397478: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-08-11 16:22:52.397488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-08-11 16:22:52.397500: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-08-11 16:22:52.397511: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-08-11 16:22:52.397522: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-08-11 16:22:52.397562: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 16:22:52.397682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 16:22:52.397766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2024-08-11 16:22:52.397786: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-08-11 16:22:52.805768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-08-11 16:22:52.805784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2024-08-11 16:22:52.805789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2024-08-11 16:22:52.805941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 16:22:52.806103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 16:22:52.806226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 16:22:52.806326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9575 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "HEIGHT = 64\n",
    "WIDTH = 64\n",
    "TIME = 176\n",
    "CHANNEL = 1\n",
    "input_shape = (None,HEIGHT, WIDTH,TIME, CHANNEL)\n",
    "input = layers.Input(shape=(input_shape[1:]))\n",
    "x = input\n",
    "\n",
    "x = Conv2Plus1D(filters=32, kernel_size=(5, 5,5), padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = MaxPool3D(pool_size=(2, 2, 2))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# Block 1\n",
    "x = add_residual_block(x, 32, (3, 3, 3))\n",
    "x = MaxPool3D(pool_size=(2, 2, 2))(x)\n",
    "\n",
    "# Block 2\n",
    "x = Conv2Plus1D(filters=32, kernel_size=(3, 3,3), padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = MaxPool3D(pool_size=(2, 2, 2))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# Block 3\n",
    "x = add_residual_block(x, 64, (3, 3, 3))\n",
    "x = MaxPool3D(pool_size=(2, 2, 2))(x)\n",
    "\n",
    "\n",
    "# Block 4\n",
    "x = Conv2Plus1D(filters=32, kernel_size=(3, 3,3), padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "# x = ResizeVideo(HEIGHT // 2, WIDTH // 2)(x)\n",
    "x = MaxPool3D(pool_size=(2, 2, 1))(x)\n",
    "\n",
    "# x = layers.GlobalAveragePooling3D()(x)\n",
    "x = layers.GlobalAveragePooling3D()(x)\n",
    "# x = Dense(units=256, activation=\"relu\")(x)\n",
    "# x = Dropout(0.3)(x)\n",
    "x = Dense(units=512, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Dense(units=4, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c53dfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 64, 176, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_plus1d (Conv2Plus1D)      (None, 64, 64, 176,  5984        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 176,  128         conv2_plus1d[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 64, 64, 176,  0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D)    (None, 32, 32, 88, 3 0           re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 88, 3 0           max_pooling3d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "residual_main (ResidualMain)    (None, 32, 32, 88, 3 24832       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 32, 88, 3 0           dropout[0][0]                    \n",
      "                                                                 residual_main[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)  (None, 16, 16, 44, 3 0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_plus1d_3 (Conv2Plus1D)    (None, 16, 16, 44, 3 12352       max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 16, 16, 44, 3 128         conv2_plus1d_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 16, 16, 44, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3D)  (None, 8, 8, 22, 32) 0           re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 8, 8, 22, 32) 0           max_pooling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "project (Project)               (None, 8, 8, 22, 64) 2240        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "residual_main_1 (ResidualMain)  (None, 8, 8, 22, 64) 80384       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 8, 8, 22, 64) 0           project[0][0]                    \n",
      "                                                                 residual_main_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3D)  (None, 4, 4, 11, 64) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_plus1d_6 (Conv2Plus1D)    (None, 4, 4, 11, 32) 21568       max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 4, 4, 11, 32) 128         conv2_plus1d_6[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 4, 4, 11, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3D)  (None, 2, 2, 11, 32) 0           re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling3d (Globa (None, 32)           0           max_pooling3d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          16896       global_average_pooling3d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            2052        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 166,692\n",
      "Trainable params: 166,500\n",
      "Non-trainable params: 192\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# tf.keras.utils.plot_model(model, expand_nested=True, dpi=60, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dd48bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 16:22:53.562913: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2024-08-11 16:22:53.579491: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3699850000 Hz\n",
      "2024-08-11 16:22:54.591859: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2024-08-11 16:22:54.766339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525/525 [==============================] - 180s 337ms/step - loss: 1.6008 - accuracy: 0.2454 - val_loss: 1.5269 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.52694, saving model to /media/kashraf/TOSHIBA EXT/Dissertation/stage2/modeling/weights/3D_CNN_EEG_movie.h5\n",
      "Epoch 2/100\n",
      "525/525 [==============================] - 177s 337ms/step - loss: 1.5324 - accuracy: 0.2689 - val_loss: 1.7162 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.52694\n",
      "Epoch 3/100\n",
      "525/525 [==============================] - 180s 343ms/step - loss: 1.4899 - accuracy: 0.2853 - val_loss: 1.5760 - val_accuracy: 0.2533\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.52694\n",
      "Epoch 4/100\n",
      "525/525 [==============================] - 188s 357ms/step - loss: 1.4604 - accuracy: 0.3032 - val_loss: 1.5867 - val_accuracy: 0.2533\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.52694\n",
      "Epoch 5/100\n",
      "525/525 [==============================] - 188s 357ms/step - loss: 1.4241 - accuracy: 0.3161 - val_loss: 1.5043 - val_accuracy: 0.2517\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.52694 to 1.50432, saving model to /media/kashraf/TOSHIBA EXT/Dissertation/stage2/modeling/weights/3D_CNN_EEG_movie.h5\n",
      "Epoch 6/100\n",
      "525/525 [==============================] - 177s 338ms/step - loss: 1.3816 - accuracy: 0.3291 - val_loss: 1.5840 - val_accuracy: 0.2750\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.50432\n",
      "Epoch 7/100\n",
      "525/525 [==============================] - 176s 335ms/step - loss: 1.3586 - accuracy: 0.3535 - val_loss: 1.7468 - val_accuracy: 0.2628\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.50432\n",
      "Epoch 8/100\n",
      "525/525 [==============================] - 175s 334ms/step - loss: 1.2881 - accuracy: 0.3660 - val_loss: 1.7028 - val_accuracy: 0.2550\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.50432\n",
      "Epoch 9/100\n",
      "525/525 [==============================] - 175s 333ms/step - loss: 1.2790 - accuracy: 0.3658 - val_loss: 1.6908 - val_accuracy: 0.2533\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.50432\n",
      "Epoch 10/100\n",
      "525/525 [==============================] - 175s 334ms/step - loss: 1.2537 - accuracy: 0.3763 - val_loss: 1.5258 - val_accuracy: 0.2911\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.50432\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 11/100\n",
      "525/525 [==============================] - 175s 334ms/step - loss: 1.1548 - accuracy: 0.4037 - val_loss: 1.5761 - val_accuracy: 0.2761\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.50432\n",
      "Epoch 12/100\n",
      "525/525 [==============================] - 175s 334ms/step - loss: 1.1273 - accuracy: 0.3993 - val_loss: 1.5807 - val_accuracy: 0.2761\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.50432\n",
      "Epoch 13/100\n",
      "525/525 [==============================] - 188s 358ms/step - loss: 1.1151 - accuracy: 0.4075 - val_loss: 1.5942 - val_accuracy: 0.2744\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.50432\n",
      "Epoch 14/100\n",
      "525/525 [==============================] - 190s 362ms/step - loss: 1.0642 - accuracy: 0.4134 - val_loss: 1.6113 - val_accuracy: 0.2711\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.50432\n",
      "Epoch 15/100\n",
      "525/525 [==============================] - 180s 343ms/step - loss: 1.0811 - accuracy: 0.4065 - val_loss: 1.6260 - val_accuracy: 0.2711\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.50432\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-07.\n",
      "Epoch 16/100\n",
      "525/525 [==============================] - 177s 336ms/step - loss: 1.0849 - accuracy: 0.4230 - val_loss: 1.6325 - val_accuracy: 0.2689\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.50432\n",
      "Epoch 17/100\n",
      "525/525 [==============================] - 175s 334ms/step - loss: 1.0845 - accuracy: 0.4100 - val_loss: 1.6291 - val_accuracy: 0.2689\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.50432\n",
      "Epoch 18/100\n",
      "525/525 [==============================] - 170s 323ms/step - loss: 1.0970 - accuracy: 0.4075 - val_loss: 1.6290 - val_accuracy: 0.2683\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.50432\n",
      "Epoch 19/100\n",
      "525/525 [==============================] - 170s 325ms/step - loss: 1.0708 - accuracy: 0.4058 - val_loss: 1.6267 - val_accuracy: 0.2689\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.50432\n",
      "Epoch 20/100\n",
      "525/525 [==============================] - 173s 329ms/step - loss: 1.0568 - accuracy: 0.4191 - val_loss: 1.6259 - val_accuracy: 0.2706\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.50432\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 21/100\n",
      "525/525 [==============================] - 174s 332ms/step - loss: 1.0574 - accuracy: 0.4155 - val_loss: 1.6309 - val_accuracy: 0.2678\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.50432\n",
      "Epoch 22/100\n",
      "525/525 [==============================] - 175s 333ms/step - loss: 1.0885 - accuracy: 0.4238 - val_loss: 1.6287 - val_accuracy: 0.2683\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.50432\n",
      "Epoch 23/100\n",
      "525/525 [==============================] - 176s 335ms/step - loss: 1.0791 - accuracy: 0.4075 - val_loss: 1.6336 - val_accuracy: 0.2689\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.50432\n",
      "Epoch 24/100\n",
      "525/525 [==============================] - 175s 333ms/step - loss: 1.0359 - accuracy: 0.4193 - val_loss: 1.6264 - val_accuracy: 0.2700\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.50432\n",
      "Epoch 25/100\n",
      "525/525 [==============================] - ETA: 0s - loss: 1.0909 - accuracy: 0.4279"
     ]
    }
   ],
   "source": [
    "             \n",
    "checkpoint = ModelCheckpoint(\"/media/kashraf/TOSHIBA EXT/Dissertation/stage2/modeling/weights/3D_CNN_EEG_movie.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 20,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                              factor = 0.01,\n",
    "                              patience = 5,\n",
    "                              verbose = 1,\n",
    "                              min_delta = 0.0001)\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [ checkpoint,reduce_lr,earlystop]\n",
    "\n",
    "# We use a very small learning rate \n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = Adam(),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "history= model.fit(   \n",
    "    train_gen,\n",
    "    epochs = epochs,\n",
    "    callbacks =callbacks,\n",
    "    validation_data = validation_gen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
